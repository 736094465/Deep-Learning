{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-30T10:28:13.767549Z",
     "start_time": "2019-08-30T10:28:11.696149Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#! -*- coding:utf-8 -*-\n",
    "import re, os, json, codecs, gc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from random import choice\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import KFold\n",
    "from keras_bert import load_trained_model_from_checkpoint, Tokenizer\n",
    "\n",
    "from keras.layers import *\n",
    "from keras.callbacks import *\n",
    "from keras.models import Model\n",
    "import keras.backend as K\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('../input/training_set.csv',encoding='gbk')\n",
    "test_df = pd.read_csv('../input/test_set.csv',encoding='gbk')\n",
    "#vali_df = pd.read_csv('../input/validation_set.csv',encoding='gb18030')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_df = pd.concat([train_df, vali_df], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24613, 2)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>飞扬 哥哥 晚上 好</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>请说出 韩国 最佳 女子 组合 几个</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>觉得 做 那种 人 最 幸福</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>雨涵 这次 不错</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>暗黑 破坏神 最 穿越 多久 没 更</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 text    labels\n",
       "0          飞扬 哥哥 晚上 好  positive\n",
       "1  请说出 韩国 最佳 女子 组合 几个  positive\n",
       "2      觉得 做 那种 人 最 幸福  positive\n",
       "3            雨涵 这次 不错  positive\n",
       "4  暗黑 破坏神 最 穿越 多久 没 更  negative"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dit = {'positive':0,'negative':1}\n",
    "train_df['labels'] = train_df['labels'].map(dit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>飞扬 哥哥 晚上 好</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>请说出 韩国 最佳 女子 组合 几个</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>觉得 做 那种 人 最 幸福</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>雨涵 这次 不错</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>暗黑 破坏神 最 穿越 多久 没 更</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 text  labels\n",
       "0          飞扬 哥哥 晚上 好       0\n",
       "1  请说出 韩国 最佳 女子 组合 几个       0\n",
       "2      觉得 做 那种 人 最 幸福       0\n",
       "3            雨涵 这次 不错       0\n",
       "4  暗黑 破坏神 最 穿越 多久 没 更       1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-30T10:28:21.257270Z",
     "start_time": "2019-08-30T10:28:21.150859Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#! -*- coding:utf-8 -*-\n",
    "import re, os, json, codecs, gc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from random import choice\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import KFold\n",
    "from keras_bert import load_trained_model_from_checkpoint, Tokenizer\n",
    "\n",
    "from keras.layers import *\n",
    "from keras.callbacks import *\n",
    "from keras.models import Model\n",
    "import keras.backend as K\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "maxlen = 512\n",
    "# config_path = '../bert/chinese_wwm_ext_L-12_H-768_A-12/bert_config.json'\n",
    "# # checkpoint_path = '/export/home/liuyuzhong/kaggle/bert/chinese_L-12_H-768_A-12/bert_model.ckpt'\n",
    "# checkpoint_path = '../bert/chinese_wwm_ext_L-12_H-768_A-12/bert_model.ckpt'\n",
    "# dict_path = '../bert/chinese_wwm_ext_L-12_H-768_A-12/vocab.txt'\n",
    "\n",
    "config_path = '../bert/roeberta_zh_L-24_H-1024_A-16/bert_config_large.json'\n",
    "# checkpoint_path = '/export/home/liuyuzhong/kaggle/bert/chinese_L-12_H-768_A-12/bert_model.ckpt'\n",
    "checkpoint_path = '../bert/roeberta_zh_L-24_H-1024_A-16/roberta_zh_large_model.ckpt'\n",
    "dict_path = '../bert/roeberta_zh_L-24_H-1024_A-16/vocab.txt'\n",
    "\n",
    "\n",
    "token_dict = {}\n",
    "with codecs.open(dict_path, 'r', 'utf8') as reader:\n",
    "    for line in reader:\n",
    "        token = line.strip()\n",
    "        token_dict[token] = len(token_dict)\n",
    "\n",
    "class OurTokenizer(Tokenizer):\n",
    "    def _tokenize(self, text):\n",
    "        R = []\n",
    "        for c in text:\n",
    "            if c in self._token_dict:\n",
    "                R.append(c)\n",
    "            elif self._is_space(c):\n",
    "                R.append('[unused1]') # space类用未经训练的[unused1]表示\n",
    "            else:\n",
    "                R.append('[UNK]') # 剩余的字符是[UNK]\n",
    "        return R\n",
    "\n",
    "tokenizer = OurTokenizer(token_dict)\n",
    "\n",
    "def seq_padding(X, padding=0):\n",
    "    L = [len(x) for x in X]\n",
    "    ML = max(L)\n",
    "    return np.array([\n",
    "        np.concatenate([x, [padding] * (ML - len(x))]) if len(x) < ML else x for x in X\n",
    "    ])\n",
    "\n",
    "class data_generator:\n",
    "    def __init__(self, data, batch_size=4, shuffle=True):\n",
    "        self.data = data\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        self.steps = len(self.data) // self.batch_size\n",
    "        if len(self.data) % self.batch_size != 0:\n",
    "            self.steps += 1\n",
    "    def __len__(self):\n",
    "        return self.steps\n",
    "    def __iter__(self):\n",
    "        while True:\n",
    "            idxs = list(range(len(self.data)))\n",
    "            \n",
    "            if self.shuffle:\n",
    "                np.random.shuffle(idxs)\n",
    "            \n",
    "            X1, X2, Y = [], [], []\n",
    "            for i in idxs:\n",
    "                d = self.data[i]\n",
    "                text = d[0][:maxlen]\n",
    "                x1, x2 = tokenizer.encode(first=text)\n",
    "                y = d[1]\n",
    "                X1.append(x1)\n",
    "                X2.append(x2)\n",
    "                Y.append([y])\n",
    "                if len(X1) == self.batch_size or i == idxs[-1]:\n",
    "                    X1 = seq_padding(X1)\n",
    "                    X2 = seq_padding(X2)\n",
    "                    Y = seq_padding(Y)\n",
    "                    yield [X1, X2], Y[:, 0, :]\n",
    "                    [X1, X2, Y] = [], [], []\n",
    "\n",
    "from keras.metrics import top_k_categorical_accuracy\n",
    "def acc_top2(y_true, y_pred):\n",
    "    return top_k_categorical_accuracy(y_true, y_pred, k=2)\n",
    "                    \n",
    "def build_bert(nclass):\n",
    "    bert_model = load_trained_model_from_checkpoint(config_path, checkpoint_path, seq_len=None)\n",
    "\n",
    "    for l in bert_model.layers:\n",
    "        l.trainable = True\n",
    "\n",
    "    x1_in = Input(shape=(None,))\n",
    "    x2_in = Input(shape=(None,))\n",
    "\n",
    "    x = bert_model([x1_in, x2_in])\n",
    "    x = Lambda(lambda x: x[:, 0])(x)\n",
    "    p = Dense(nclass, activation='softmax')(x)\n",
    "\n",
    "    model = Model([x1_in, x2_in], p)\n",
    "    model.compile(loss='categorical_crossentropy', \n",
    "                  optimizer=Adam(1e-5),\n",
    "                  metrics=['accuracy', acc_top2])\n",
    "    print(model.summary())\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-30T10:28:22.788539Z",
     "start_time": "2019-08-30T10:28:22.533994Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "\n",
    "DATA_LIST = []\n",
    "for data_row in train_df.iloc[:].itertuples():\n",
    "    DATA_LIST.append((data_row.text, to_categorical(data_row.labels, 2)))\n",
    "DATA_LIST = np.array(DATA_LIST)\n",
    "\n",
    "DATA_LIST_TEST = []\n",
    "for data_row in test_df.iloc[:].itertuples():\n",
    "    DATA_LIST_TEST.append((data_row.text, to_categorical(0, 2)))\n",
    "DATA_LIST_TEST = np.array(DATA_LIST_TEST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-30T10:28:24.868418Z",
     "start_time": "2019-08-30T10:28:24.847638Z"
    }
   },
   "outputs": [],
   "source": [
    "def run_cv(nfold, data, data_label, data_test):\n",
    "    kf = KFold(n_splits=nfold, shuffle=True, random_state=520).split(data)\n",
    "    train_model_pred = np.zeros((len(data), 2))\n",
    "    test_model_pred = np.zeros((len(data_test), 2))\n",
    "\n",
    "    for i, (train_fold, test_fold) in enumerate(kf):\n",
    "        X_train, X_valid, = data[train_fold, :], data[test_fold, :]\n",
    "        \n",
    "        model = build_bert(2)\n",
    "        early_stopping = EarlyStopping(monitor='val_acc', patience=4)\n",
    "        plateau = ReduceLROnPlateau(monitor=\"val_acc\", verbose=1, mode='max', factor=0.5, patience=1)\n",
    "        checkpoint = ModelCheckpoint('./bert_dump/' + str(i) + '.hdf5', monitor='val_acc', \n",
    "                                         verbose=2, save_best_only=True, mode='max',save_weights_only=True)\n",
    "        \n",
    "        train_D = data_generator(X_train, shuffle=True)\n",
    "        valid_D = data_generator(X_valid, shuffle=True)\n",
    "        test_D = data_generator(data_test, shuffle=False)\n",
    "        \n",
    "        model.fit_generator(\n",
    "            train_D.__iter__(),\n",
    "            steps_per_epoch=len(train_D),\n",
    "            epochs=15,\n",
    "            validation_data=valid_D.__iter__(),\n",
    "            validation_steps=len(valid_D),\n",
    "            callbacks=[early_stopping, plateau, checkpoint],\n",
    "        )\n",
    "        \n",
    "        # model.load_weights('./bert_dump/' + str(i) + '.hdf5')\n",
    "        \n",
    "        # return model\n",
    "        train_model_pred[test_fold, :] =  model.predict_generator(valid_D.__iter__(), steps=len(valid_D),verbose=1)\n",
    "        test_model_pred += model.predict_generator(test_D.__iter__(), steps=len(test_D),verbose=1)\n",
    "        \n",
    "        del model; gc.collect()\n",
    "        K.clear_session()\n",
    "        \n",
    "        # break\n",
    "        \n",
    "    return train_model_pred, test_model_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-30T10:29:16.816348Z",
     "start_time": "2019-08-30T10:28:25.966794Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0922 22:51:17.167338 140464086943552 deprecation_wrapper.py:119] From /home/qishao/anaconda3/envs/qishao/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0922 22:51:17.181102 140464086943552 deprecation_wrapper.py:119] From /home/qishao/anaconda3/envs/qishao/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0922 22:51:17.229848 140464086943552 deprecation_wrapper.py:119] From /home/qishao/anaconda3/envs/qishao/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:131: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0922 22:51:17.230735 140464086943552 deprecation_wrapper.py:119] From /home/qishao/anaconda3/envs/qishao/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "W0922 22:51:17.237863 140464086943552 deprecation.py:506] From /home/qishao/anaconda3/envs/qishao/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "W0922 22:51:17.269602 140464086943552 deprecation_wrapper.py:119] From /home/qishao/anaconda3/envs/qishao/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:4185: The name tf.truncated_normal is deprecated. Please use tf.random.truncated_normal instead.\n",
      "\n",
      "W0922 22:52:10.032811 140464086943552 deprecation_wrapper.py:119] From /home/qishao/anaconda3/envs/qishao/lib/python3.6/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W0922 22:52:10.208477 140464086943552 deprecation.py:323] From /home/qishao/anaconda3/envs/qishao/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "model_2 (Model)                 (None, None, 1024)   324472832   input_1[0][0]                    \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 1024)         0           model_2[1][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 2)            2050        lambda_1[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 324,474,882\n",
      "Trainable params: 324,474,882\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Epoch 1/15\n",
      "5538/5538 [==============================] - 1769s 319ms/step - loss: 0.1546 - acc: 0.9459 - acc_top2: 1.0000 - val_loss: 0.0939 - val_acc: 0.9691 - val_acc_top2: 1.0000\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.96913, saving model to ./bert_dump/0.hdf5\n",
      "Epoch 2/15\n",
      "5538/5538 [==============================] - 1739s 314ms/step - loss: 0.0597 - acc: 0.9809 - acc_top2: 1.0000 - val_loss: 0.0985 - val_acc: 0.9744 - val_acc_top2: 1.0000\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.96913 to 0.97441, saving model to ./bert_dump/0.hdf5\n",
      "Epoch 3/15\n",
      "5538/5538 [==============================] - 1738s 314ms/step - loss: 0.0355 - acc: 0.9890 - acc_top2: 1.0000 - val_loss: 0.0964 - val_acc: 0.9756 - val_acc_top2: 1.0000\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.97441 to 0.97563, saving model to ./bert_dump/0.hdf5\n",
      "Epoch 4/15\n",
      "5538/5538 [==============================] - 1739s 314ms/step - loss: 0.0278 - acc: 0.9923 - acc_top2: 1.0000 - val_loss: 0.1314 - val_acc: 0.9756 - val_acc_top2: 1.0000\n",
      "\n",
      "Epoch 00004: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-06.\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.97563\n",
      "Epoch 5/15\n",
      "5538/5538 [==============================] - 1739s 314ms/step - loss: 0.0101 - acc: 0.9974 - acc_top2: 1.0000 - val_loss: 0.1143 - val_acc: 0.9801 - val_acc_top2: 1.0000\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.97563 to 0.98010, saving model to ./bert_dump/0.hdf5\n",
      "Epoch 6/15\n",
      "5538/5538 [==============================] - 1738s 314ms/step - loss: 0.0056 - acc: 0.9985 - acc_top2: 1.0000 - val_loss: 0.1095 - val_acc: 0.9858 - val_acc_top2: 1.0000\n",
      "\n",
      "Epoch 00006: val_acc improved from 0.98010 to 0.98578, saving model to ./bert_dump/0.hdf5\n",
      "Epoch 7/15\n",
      "5538/5538 [==============================] - 1738s 314ms/step - loss: 0.0050 - acc: 0.9987 - acc_top2: 1.0000 - val_loss: 0.1552 - val_acc: 0.9821 - val_acc_top2: 1.0000\n",
      "\n",
      "Epoch 00007: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-06.\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.98578\n",
      "Epoch 8/15\n",
      "5538/5538 [==============================] - 1739s 314ms/step - loss: 0.0018 - acc: 0.9996 - acc_top2: 1.0000 - val_loss: 0.1595 - val_acc: 0.9842 - val_acc_top2: 1.0000\n",
      "\n",
      "Epoch 00008: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-06.\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.98578\n",
      "Epoch 9/15\n",
      "5538/5538 [==============================] - 1739s 314ms/step - loss: 8.0834e-04 - acc: 0.9998 - acc_top2: 1.0000 - val_loss: 0.1621 - val_acc: 0.9825 - val_acc_top2: 1.0000\n",
      "\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-07.\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.98578\n",
      "Epoch 10/15\n",
      "5538/5538 [==============================] - 1739s 314ms/step - loss: 1.9394e-04 - acc: 1.0000 - acc_top2: 1.0000 - val_loss: 0.1650 - val_acc: 0.9838 - val_acc_top2: 1.0000\n",
      "\n",
      "Epoch 00010: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-07.\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.98578\n",
      "616/616 [==============================] - 24s 39ms/step\n",
      "1250/1250 [==============================] - 42s 33ms/step\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "model_2 (Model)                 (None, None, 1024)   324472832   input_1[0][0]                    \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 1024)         0           model_2[1][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 2)            2050        lambda_1[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 324,474,882\n",
      "Trainable params: 324,474,882\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Epoch 1/15\n",
      "5538/5538 [==============================] - 1776s 321ms/step - loss: 0.1557 - acc: 0.9440 - acc_top2: 1.0000 - val_loss: 0.1295 - val_acc: 0.9569 - val_acc_top2: 1.0000\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.95695, saving model to ./bert_dump/1.hdf5\n",
      "Epoch 2/15\n",
      "5538/5538 [==============================] - 1747s 315ms/step - loss: 0.0591 - acc: 0.9815 - acc_top2: 1.0000 - val_loss: 0.0728 - val_acc: 0.9760 - val_acc_top2: 1.0000\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.95695 to 0.97604, saving model to ./bert_dump/1.hdf5\n",
      "Epoch 3/15\n",
      "5538/5538 [==============================] - 1747s 315ms/step - loss: 0.0377 - acc: 0.9873 - acc_top2: 1.0000 - val_loss: 0.0790 - val_acc: 0.9793 - val_acc_top2: 1.0000\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.97604 to 0.97929, saving model to ./bert_dump/1.hdf5\n",
      "Epoch 4/15\n",
      "5538/5538 [==============================] - 1746s 315ms/step - loss: 0.0274 - acc: 0.9912 - acc_top2: 1.0000 - val_loss: 0.0891 - val_acc: 0.9756 - val_acc_top2: 1.0000\n",
      "\n",
      "Epoch 00004: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-06.\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.97929\n",
      "Epoch 5/15\n",
      "5538/5538 [==============================] - 1747s 315ms/step - loss: 0.0106 - acc: 0.9968 - acc_top2: 1.0000 - val_loss: 0.0698 - val_acc: 0.9805 - val_acc_top2: 1.0000\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.97929 to 0.98050, saving model to ./bert_dump/1.hdf5\n",
      "Epoch 6/15\n",
      "5538/5538 [==============================] - 1747s 315ms/step - loss: 0.0063 - acc: 0.9982 - acc_top2: 1.0000 - val_loss: 0.0921 - val_acc: 0.9825 - val_acc_top2: 1.0000\n",
      "\n",
      "Epoch 00006: val_acc improved from 0.98050 to 0.98253, saving model to ./bert_dump/1.hdf5\n",
      "Epoch 7/15\n",
      "5538/5538 [==============================] - 1747s 315ms/step - loss: 0.0058 - acc: 0.9986 - acc_top2: 1.0000 - val_loss: 0.1004 - val_acc: 0.9833 - val_acc_top2: 1.0000\n",
      "\n",
      "Epoch 00007: val_acc improved from 0.98253 to 0.98335, saving model to ./bert_dump/1.hdf5\n",
      "Epoch 8/15\n",
      "5538/5538 [==============================] - 1747s 315ms/step - loss: 0.0047 - acc: 0.9991 - acc_top2: 1.0000 - val_loss: 0.1288 - val_acc: 0.9801 - val_acc_top2: 1.0000\n",
      "\n",
      "Epoch 00008: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-06.\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.98335\n",
      "Epoch 9/15\n",
      "5538/5538 [==============================] - 1748s 316ms/step - loss: 0.0023 - acc: 0.9995 - acc_top2: 1.0000 - val_loss: 0.1288 - val_acc: 0.9833 - val_acc_top2: 1.0000\n",
      "\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-06.\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.98335\n",
      "Epoch 10/15\n",
      "5538/5538 [==============================] - 1748s 316ms/step - loss: 7.2769e-05 - acc: 1.0000 - acc_top2: 1.0000 - val_loss: 0.1683 - val_acc: 0.9838 - val_acc_top2: 1.0000\n",
      "\n",
      "Epoch 00010: val_acc improved from 0.98335 to 0.98375, saving model to ./bert_dump/1.hdf5\n",
      "Epoch 11/15\n",
      "5538/5538 [==============================] - 1749s 316ms/step - loss: 3.2912e-06 - acc: 1.0000 - acc_top2: 1.0000 - val_loss: 0.2020 - val_acc: 0.9817 - val_acc_top2: 1.0000\n",
      "\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-07.\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.98375\n",
      "Epoch 12/15\n",
      "5538/5538 [==============================] - 1751s 316ms/step - loss: 6.8235e-06 - acc: 1.0000 - acc_top2: 1.0000 - val_loss: 0.2121 - val_acc: 0.9829 - val_acc_top2: 1.0000\n",
      "\n",
      "Epoch 00012: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-07.\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.98375\n",
      "Epoch 13/15\n",
      "5538/5538 [==============================] - 1743s 315ms/step - loss: 3.8361e-04 - acc: 1.0000 - acc_top2: 1.0000 - val_loss: 0.2076 - val_acc: 0.9833 - val_acc_top2: 1.0000\n",
      "\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-07.\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.98375\n",
      "Epoch 14/15\n",
      "5538/5538 [==============================] - 1743s 315ms/step - loss: 7.0772e-04 - acc: 1.0000 - acc_top2: 1.0000 - val_loss: 0.2065 - val_acc: 0.9833 - val_acc_top2: 1.0000\n",
      "\n",
      "Epoch 00014: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-08.\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.98375\n",
      "616/616 [==============================] - 24s 39ms/step\n",
      "1250/1250 [==============================] - 41s 33ms/step\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "model_2 (Model)                 (None, None, 1024)   324472832   input_1[0][0]                    \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 1024)         0           model_2[1][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 2)            2050        lambda_1[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 324,474,882\n",
      "Trainable params: 324,474,882\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Epoch 1/15\n",
      "5538/5538 [==============================] - 1750s 316ms/step - loss: 0.1574 - acc: 0.9447 - acc_top2: 1.0000 - val_loss: 0.0989 - val_acc: 0.9659 - val_acc_top2: 1.0000\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.96588, saving model to ./bert_dump/2.hdf5\n",
      "Epoch 2/15\n",
      "5538/5538 [==============================] - 1720s 311ms/step - loss: 0.0683 - acc: 0.9784 - acc_top2: 1.0000 - val_loss: 0.0800 - val_acc: 0.9740 - val_acc_top2: 1.0000\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.96588 to 0.97400, saving model to ./bert_dump/2.hdf5\n",
      "Epoch 3/15\n",
      "5538/5538 [==============================] - 1720s 311ms/step - loss: 0.0409 - acc: 0.9881 - acc_top2: 1.0000 - val_loss: 0.0687 - val_acc: 0.9768 - val_acc_top2: 1.0000\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.97400 to 0.97685, saving model to ./bert_dump/2.hdf5\n",
      "Epoch 4/15\n",
      "5538/5538 [==============================] - 1719s 310ms/step - loss: 0.0270 - acc: 0.9921 - acc_top2: 1.0000 - val_loss: 0.1669 - val_acc: 0.9521 - val_acc_top2: 1.0000\n",
      "\n",
      "Epoch 00004: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-06.\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.97685\n",
      "Epoch 5/15\n",
      "5538/5538 [==============================] - 1718s 310ms/step - loss: 0.0098 - acc: 0.9969 - acc_top2: 1.0000 - val_loss: 0.1251 - val_acc: 0.9781 - val_acc_top2: 1.0000\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.97685 to 0.97807, saving model to ./bert_dump/2.hdf5\n",
      "Epoch 6/15\n",
      "5538/5538 [==============================] - 1717s 310ms/step - loss: 0.0087 - acc: 0.9977 - acc_top2: 1.0000 - val_loss: 0.1024 - val_acc: 0.9797 - val_acc_top2: 1.0000\n",
      "\n",
      "Epoch 00006: val_acc improved from 0.97807 to 0.97969, saving model to ./bert_dump/2.hdf5\n",
      "Epoch 7/15\n",
      "5538/5538 [==============================] - 1719s 310ms/step - loss: 0.0039 - acc: 0.9986 - acc_top2: 1.0000 - val_loss: 0.1115 - val_acc: 0.9809 - val_acc_top2: 1.0000\n",
      "\n",
      "Epoch 00007: val_acc improved from 0.97969 to 0.98091, saving model to ./bert_dump/2.hdf5\n",
      "Epoch 8/15\n",
      "5538/5538 [==============================] - 1718s 310ms/step - loss: 0.0052 - acc: 0.9985 - acc_top2: 1.0000 - val_loss: 0.1179 - val_acc: 0.9809 - val_acc_top2: 1.0000\n",
      "\n",
      "Epoch 00008: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-06.\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.98091\n",
      "Epoch 9/15\n",
      "5538/5538 [==============================] - 1717s 310ms/step - loss: 0.0021 - acc: 0.9996 - acc_top2: 1.0000 - val_loss: 0.1330 - val_acc: 0.9813 - val_acc_top2: 1.0000\n",
      "\n",
      "Epoch 00009: val_acc improved from 0.98091 to 0.98132, saving model to ./bert_dump/2.hdf5\n",
      "Epoch 10/15\n",
      "5538/5538 [==============================] - 1716s 310ms/step - loss: 0.0011 - acc: 0.9997 - acc_top2: 1.0000 - val_loss: 0.1330 - val_acc: 0.9825 - val_acc_top2: 1.0000\n",
      "\n",
      "Epoch 00010: val_acc improved from 0.98132 to 0.98253, saving model to ./bert_dump/2.hdf5\n",
      "Epoch 11/15\n",
      "5538/5538 [==============================] - 1716s 310ms/step - loss: 1.1138e-04 - acc: 1.0000 - acc_top2: 1.0000 - val_loss: 0.2255 - val_acc: 0.9829 - val_acc_top2: 1.0000\n",
      "\n",
      "Epoch 00011: val_acc improved from 0.98253 to 0.98294, saving model to ./bert_dump/2.hdf5\n",
      "Epoch 12/15\n",
      "5538/5538 [==============================] - 1717s 310ms/step - loss: 8.8421e-04 - acc: 0.9997 - acc_top2: 1.0000 - val_loss: 0.1884 - val_acc: 0.9821 - val_acc_top2: 1.0000\n",
      "\n",
      "Epoch 00012: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-06.\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.98294\n",
      "Epoch 13/15\n",
      "5538/5538 [==============================] - 1717s 310ms/step - loss: 5.3488e-04 - acc: 0.9999 - acc_top2: 1.0000 - val_loss: 0.1852 - val_acc: 0.9805 - val_acc_top2: 1.0000\n",
      "\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-07.\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.98294\n",
      "Epoch 14/15\n",
      "5538/5538 [==============================] - 1716s 310ms/step - loss: 2.6457e-06 - acc: 1.0000 - acc_top2: 1.0000 - val_loss: 0.2004 - val_acc: 0.9813 - val_acc_top2: 1.0000\n",
      "\n",
      "Epoch 00014: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-07.\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.98294\n",
      "Epoch 15/15\n",
      "5538/5538 [==============================] - 1717s 310ms/step - loss: 1.8723e-06 - acc: 1.0000 - acc_top2: 1.0000 - val_loss: 0.2125 - val_acc: 0.9805 - val_acc_top2: 1.0000\n",
      "\n",
      "Epoch 00015: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-07.\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.98294\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "616/616 [==============================] - 25s 40ms/step\n",
      "1250/1250 [==============================] - 43s 34ms/step\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "model_2 (Model)                 (None, None, 1024)   324472832   input_1[0][0]                    \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 1024)         0           model_2[1][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 2)            2050        lambda_1[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 324,474,882\n",
      "Trainable params: 324,474,882\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Epoch 1/15\n",
      "5538/5538 [==============================] - 1771s 320ms/step - loss: 0.1465 - acc: 0.9481 - acc_top2: 1.0000 - val_loss: 0.0968 - val_acc: 0.9695 - val_acc_top2: 1.0000\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.96952, saving model to ./bert_dump/3.hdf5\n",
      "Epoch 2/15\n",
      "5538/5538 [==============================] - 1740s 314ms/step - loss: 0.0639 - acc: 0.9789 - acc_top2: 1.0000 - val_loss: 0.0846 - val_acc: 0.9728 - val_acc_top2: 1.0000\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.96952 to 0.97278, saving model to ./bert_dump/3.hdf5\n",
      "Epoch 3/15\n",
      "5538/5538 [==============================] - 1740s 314ms/step - loss: 0.0371 - acc: 0.9893 - acc_top2: 1.0000 - val_loss: 0.0775 - val_acc: 0.9728 - val_acc_top2: 1.0000\n",
      "\n",
      "Epoch 00003: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-06.\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.97278\n",
      "Epoch 4/15\n",
      "5538/5538 [==============================] - 1739s 314ms/step - loss: 0.0167 - acc: 0.9952 - acc_top2: 1.0000 - val_loss: 0.0996 - val_acc: 0.9748 - val_acc_top2: 1.0000\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.97278 to 0.97481, saving model to ./bert_dump/3.hdf5\n",
      "Epoch 5/15\n",
      "5538/5538 [==============================] - 1740s 314ms/step - loss: 0.0073 - acc: 0.9979 - acc_top2: 1.0000 - val_loss: 0.1239 - val_acc: 0.9785 - val_acc_top2: 1.0000\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.97481 to 0.97846, saving model to ./bert_dump/3.hdf5\n",
      "Epoch 6/15\n",
      "5538/5538 [==============================] - 1732s 313ms/step - loss: 0.0064 - acc: 0.9979 - acc_top2: 1.0000 - val_loss: 0.1757 - val_acc: 0.9785 - val_acc_top2: 1.0000\n",
      "\n",
      "Epoch 00006: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-06.\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.97846\n",
      "Epoch 7/15\n",
      "5538/5538 [==============================] - 1727s 312ms/step - loss: 0.0038 - acc: 0.9992 - acc_top2: 1.0000 - val_loss: 0.1483 - val_acc: 0.9768 - val_acc_top2: 1.0000\n",
      "\n",
      "Epoch 00007: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-06.\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.97846\n",
      "Epoch 8/15\n",
      "5538/5538 [==============================] - 1726s 312ms/step - loss: 0.0013 - acc: 0.9996 - acc_top2: 1.0000 - val_loss: 0.1317 - val_acc: 0.9817 - val_acc_top2: 1.0000\n",
      "\n",
      "Epoch 00008: val_acc improved from 0.97846 to 0.98171, saving model to ./bert_dump/3.hdf5\n",
      "Epoch 9/15\n",
      "5538/5538 [==============================] - 1726s 312ms/step - loss: 2.6698e-04 - acc: 0.9999 - acc_top2: 1.0000 - val_loss: 0.1924 - val_acc: 0.9785 - val_acc_top2: 1.0000\n",
      "\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-07.\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.98171\n",
      "Epoch 10/15\n",
      "5538/5538 [==============================] - 1725s 311ms/step - loss: 8.3868e-05 - acc: 1.0000 - acc_top2: 1.0000 - val_loss: 0.1978 - val_acc: 0.9781 - val_acc_top2: 1.0000\n",
      "\n",
      "Epoch 00010: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-07.\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.98171\n",
      "Epoch 11/15\n",
      "5538/5538 [==============================] - 1724s 311ms/step - loss: 9.3227e-05 - acc: 1.0000 - acc_top2: 1.0000 - val_loss: 0.1897 - val_acc: 0.9813 - val_acc_top2: 1.0000\n",
      "\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-07.\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.98171\n",
      "Epoch 12/15\n",
      "5538/5538 [==============================] - 1725s 311ms/step - loss: 9.8932e-06 - acc: 1.0000 - acc_top2: 1.0000 - val_loss: 0.1953 - val_acc: 0.9817 - val_acc_top2: 1.0000\n",
      "\n",
      "Epoch 00012: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-08.\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.98171\n",
      "616/616 [==============================] - 24s 39ms/step\n",
      "1250/1250 [==============================] - 42s 33ms/step\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "model_2 (Model)                 (None, None, 1024)   324472832   input_1[0][0]                    \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 1024)         0           model_2[1][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 2)            2050        lambda_1[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 324,474,882\n",
      "Trainable params: 324,474,882\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Epoch 1/15\n",
      "5538/5538 [==============================] - 1763s 318ms/step - loss: 0.1504 - acc: 0.9468 - acc_top2: 1.0000 - val_loss: 0.0900 - val_acc: 0.9740 - val_acc_top2: 1.0000\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.97399, saving model to ./bert_dump/4.hdf5\n",
      "Epoch 2/15\n",
      "5538/5538 [==============================] - 1734s 313ms/step - loss: 0.0599 - acc: 0.9810 - acc_top2: 1.0000 - val_loss: 0.0903 - val_acc: 0.9760 - val_acc_top2: 1.0000\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.97399 to 0.97603, saving model to ./bert_dump/4.hdf5\n",
      "Epoch 3/15\n",
      "5538/5538 [==============================] - 1733s 313ms/step - loss: 0.0411 - acc: 0.9884 - acc_top2: 1.0000 - val_loss: 0.0605 - val_acc: 0.9825 - val_acc_top2: 1.0000\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.97603 to 0.98253, saving model to ./bert_dump/4.hdf5\n",
      "Epoch 4/15\n",
      "5538/5538 [==============================] - 1732s 313ms/step - loss: 0.0271 - acc: 0.9918 - acc_top2: 1.0000 - val_loss: 0.0855 - val_acc: 0.9817 - val_acc_top2: 1.0000\n",
      "\n",
      "Epoch 00004: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-06.\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.98253\n",
      "Epoch 5/15\n",
      "5538/5538 [==============================] - 1733s 313ms/step - loss: 0.0089 - acc: 0.9972 - acc_top2: 1.0000 - val_loss: 0.1050 - val_acc: 0.9793 - val_acc_top2: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00005: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-06.\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.98253\n",
      "Epoch 6/15\n",
      "5538/5538 [==============================] - 1749s 316ms/step - loss: 0.0031 - acc: 0.9994 - acc_top2: 1.0000 - val_loss: 0.1131 - val_acc: 0.9846 - val_acc_top2: 1.0000\n",
      "\n",
      "Epoch 00006: val_acc improved from 0.98253 to 0.98456, saving model to ./bert_dump/4.hdf5\n",
      "Epoch 7/15\n",
      "5538/5538 [==============================] - 1749s 316ms/step - loss: 0.0023 - acc: 0.9994 - acc_top2: 1.0000 - val_loss: 0.0973 - val_acc: 0.9846 - val_acc_top2: 1.0000\n",
      "\n",
      "Epoch 00007: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-06.\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.98456\n",
      "Epoch 8/15\n",
      "5538/5538 [==============================] - 1750s 316ms/step - loss: 7.6125e-04 - acc: 0.9998 - acc_top2: 1.0000 - val_loss: 0.1082 - val_acc: 0.9846 - val_acc_top2: 1.0000\n",
      "\n",
      "Epoch 00008: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-07.\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.98456\n",
      "Epoch 9/15\n",
      "5538/5538 [==============================] - 1750s 316ms/step - loss: 3.2813e-04 - acc: 0.9999 - acc_top2: 1.0000 - val_loss: 0.1124 - val_acc: 0.9866 - val_acc_top2: 1.0000\n",
      "\n",
      "Epoch 00009: val_acc improved from 0.98456 to 0.98659, saving model to ./bert_dump/4.hdf5\n",
      "Epoch 10/15\n",
      "5538/5538 [==============================] - 1749s 316ms/step - loss: 4.3736e-05 - acc: 1.0000 - acc_top2: 1.0000 - val_loss: 0.1272 - val_acc: 0.9862 - val_acc_top2: 1.0000\n",
      "\n",
      "Epoch 00010: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-07.\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.98659\n",
      "Epoch 11/15\n",
      "5538/5538 [==============================] - 1750s 316ms/step - loss: 2.2292e-05 - acc: 1.0000 - acc_top2: 1.0000 - val_loss: 0.1340 - val_acc: 0.9862 - val_acc_top2: 1.0000\n",
      "\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-07.\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.98659\n",
      "Epoch 12/15\n",
      "5538/5538 [==============================] - 1750s 316ms/step - loss: 8.8750e-07 - acc: 1.0000 - acc_top2: 1.0000 - val_loss: 0.1391 - val_acc: 0.9862 - val_acc_top2: 1.0000\n",
      "\n",
      "Epoch 00012: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-08.\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.98659\n",
      "Epoch 13/15\n",
      "5538/5538 [==============================] - 1750s 316ms/step - loss: 9.9881e-07 - acc: 1.0000 - acc_top2: 1.0000 - val_loss: 0.1408 - val_acc: 0.9862 - val_acc_top2: 1.0000\n",
      "\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-08.\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.98659\n",
      "616/616 [==============================] - 24s 39ms/step\n",
      "1250/1250 [==============================] - 41s 33ms/step\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "model_2 (Model)                 (None, None, 1024)   324472832   input_1[0][0]                    \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 1024)         0           model_2[1][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 2)            2050        lambda_1[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 324,474,882\n",
      "Trainable params: 324,474,882\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Epoch 1/15\n",
      "5538/5538 [==============================] - 1766s 319ms/step - loss: 0.1583 - acc: 0.9430 - acc_top2: 1.0000 - val_loss: 0.1267 - val_acc: 0.9598 - val_acc_top2: 1.0000\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.95977, saving model to ./bert_dump/5.hdf5\n",
      "Epoch 2/15\n",
      "5538/5538 [==============================] - 1735s 313ms/step - loss: 0.0639 - acc: 0.9796 - acc_top2: 1.0000 - val_loss: 0.0873 - val_acc: 0.9744 - val_acc_top2: 1.0000\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.95977 to 0.97440, saving model to ./bert_dump/5.hdf5\n",
      "Epoch 3/15\n",
      "5538/5538 [==============================] - 1735s 313ms/step - loss: 0.0392 - acc: 0.9883 - acc_top2: 1.0000 - val_loss: 0.0842 - val_acc: 0.9785 - val_acc_top2: 1.0000\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.97440 to 0.97846, saving model to ./bert_dump/5.hdf5\n",
      "Epoch 4/15\n",
      "5538/5538 [==============================] - 1735s 313ms/step - loss: 0.0286 - acc: 0.9912 - acc_top2: 1.0000 - val_loss: 0.0946 - val_acc: 0.9801 - val_acc_top2: 1.0000\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.97846 to 0.98009, saving model to ./bert_dump/5.hdf5\n",
      "Epoch 5/15\n",
      "5538/5538 [==============================] - 1735s 313ms/step - loss: 0.0233 - acc: 0.9937 - acc_top2: 1.0000 - val_loss: 0.1050 - val_acc: 0.9850 - val_acc_top2: 1.0000\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.98009 to 0.98497, saving model to ./bert_dump/5.hdf5\n",
      "Epoch 6/15\n",
      "5538/5538 [==============================] - 1736s 313ms/step - loss: 0.0204 - acc: 0.9941 - acc_top2: 1.0000 - val_loss: 0.0828 - val_acc: 0.9837 - val_acc_top2: 1.0000\n",
      "\n",
      "Epoch 00006: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-06.\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.98497\n",
      "Epoch 7/15\n",
      "5538/5538 [==============================] - 1736s 313ms/step - loss: 0.0093 - acc: 0.9972 - acc_top2: 1.0000 - val_loss: 0.0892 - val_acc: 0.9837 - val_acc_top2: 1.0000\n",
      "\n",
      "Epoch 00007: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-06.\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.98497\n",
      "Epoch 8/15\n",
      "5538/5538 [==============================] - 1735s 313ms/step - loss: 9.4923e-04 - acc: 0.9997 - acc_top2: 1.0000 - val_loss: 0.1023 - val_acc: 0.9866 - val_acc_top2: 1.0000\n",
      "\n",
      "Epoch 00008: val_acc improved from 0.98497 to 0.98659, saving model to ./bert_dump/5.hdf5\n",
      "Epoch 9/15\n",
      "5538/5538 [==============================] - 1736s 313ms/step - loss: 0.0013 - acc: 0.9998 - acc_top2: 1.0000 - val_loss: 0.1141 - val_acc: 0.9874 - val_acc_top2: 1.0000\n",
      "\n",
      "Epoch 00009: val_acc improved from 0.98659 to 0.98740, saving model to ./bert_dump/5.hdf5\n",
      "Epoch 10/15\n",
      "5538/5538 [==============================] - 1735s 313ms/step - loss: 0.0011 - acc: 0.9998 - acc_top2: 1.0000 - val_loss: 0.1093 - val_acc: 0.9874 - val_acc_top2: 1.0000\n",
      "\n",
      "Epoch 00010: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-06.\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.98740\n",
      "Epoch 11/15\n",
      "5538/5538 [==============================] - 1736s 313ms/step - loss: 6.4749e-05 - acc: 1.0000 - acc_top2: 1.0000 - val_loss: 0.1252 - val_acc: 0.9866 - val_acc_top2: 1.0000\n",
      "\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-07.\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.98740\n",
      "Epoch 12/15\n",
      "5538/5538 [==============================] - 1735s 313ms/step - loss: 7.1271e-06 - acc: 1.0000 - acc_top2: 1.0000 - val_loss: 0.1417 - val_acc: 0.9870 - val_acc_top2: 1.0000\n",
      "\n",
      "Epoch 00012: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-07.\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.98740\n",
      "Epoch 13/15\n",
      "5538/5538 [==============================] - 1736s 313ms/step - loss: 8.6673e-05 - acc: 0.9999 - acc_top2: 1.0000 - val_loss: 0.1465 - val_acc: 0.9874 - val_acc_top2: 1.0000\n",
      "\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-07.\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.98740\n",
      "616/616 [==============================] - 24s 39ms/step\n",
      "1250/1250 [==============================] - 41s 33ms/step\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "model_2 (Model)                 (None, None, 1024)   324472832   input_1[0][0]                    \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 1024)         0           model_2[1][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 2)            2050        lambda_1[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 324,474,882\n",
      "Trainable params: 324,474,882\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "5538/5538 [==============================] - 1770s 320ms/step - loss: 0.1502 - acc: 0.9464 - acc_top2: 1.0000 - val_loss: 0.0941 - val_acc: 0.9683 - val_acc_top2: 1.0000\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.96831, saving model to ./bert_dump/6.hdf5\n",
      "Epoch 2/15\n",
      "5538/5538 [==============================] - 1740s 314ms/step - loss: 0.0596 - acc: 0.9809 - acc_top2: 1.0000 - val_loss: 0.0783 - val_acc: 0.9768 - val_acc_top2: 1.0000\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.96831 to 0.97684, saving model to ./bert_dump/6.hdf5\n",
      "Epoch 3/15\n",
      "5538/5538 [==============================] - 1739s 314ms/step - loss: 0.0363 - acc: 0.9886 - acc_top2: 1.0000 - val_loss: 0.0736 - val_acc: 0.9817 - val_acc_top2: 1.0000\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.97684 to 0.98171, saving model to ./bert_dump/6.hdf5\n",
      "Epoch 4/15\n",
      "5538/5538 [==============================] - 1740s 314ms/step - loss: 0.0275 - acc: 0.9924 - acc_top2: 1.0000 - val_loss: 0.0501 - val_acc: 0.9870 - val_acc_top2: 1.0000\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.98171 to 0.98700, saving model to ./bert_dump/6.hdf5\n",
      "Epoch 5/15\n",
      "5538/5538 [==============================] - 1740s 314ms/step - loss: 0.0226 - acc: 0.9940 - acc_top2: 1.0000 - val_loss: 0.0569 - val_acc: 0.9858 - val_acc_top2: 1.0000\n",
      "\n",
      "Epoch 00005: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-06.\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.98700\n",
      "Epoch 6/15\n",
      "5538/5538 [==============================] - 1740s 314ms/step - loss: 0.0094 - acc: 0.9976 - acc_top2: 1.0000 - val_loss: 0.0442 - val_acc: 0.9866 - val_acc_top2: 1.0000\n",
      "\n",
      "Epoch 00006: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-06.\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.98700\n",
      "Epoch 7/15\n",
      "5538/5538 [==============================] - 1741s 314ms/step - loss: 0.0013 - acc: 0.9997 - acc_top2: 1.0000 - val_loss: 0.0924 - val_acc: 0.9870 - val_acc_top2: 1.0000\n",
      "\n",
      "Epoch 00007: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-06.\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.98700\n",
      "Epoch 8/15\n",
      "5538/5538 [==============================] - 1741s 314ms/step - loss: 0.0013 - acc: 0.9998 - acc_top2: 1.0000 - val_loss: 0.0917 - val_acc: 0.9866 - val_acc_top2: 1.0000\n",
      "\n",
      "Epoch 00008: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-07.\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.98700\n",
      "616/616 [==============================] - 24s 39ms/step\n",
      "1250/1250 [==============================] - 41s 33ms/step\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "model_2 (Model)                 (None, None, 1024)   324472832   input_1[0][0]                    \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 1024)         0           model_2[1][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 2)            2050        lambda_1[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 324,474,882\n",
      "Trainable params: 324,474,882\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Epoch 1/15\n",
      "5538/5538 [==============================] - 1777s 321ms/step - loss: 0.1531 - acc: 0.9477 - acc_top2: 1.0000 - val_loss: 0.0808 - val_acc: 0.9707 - val_acc_top2: 1.0000\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.97074, saving model to ./bert_dump/7.hdf5\n",
      "Epoch 2/15\n",
      "5538/5538 [==============================] - 1747s 316ms/step - loss: 0.0599 - acc: 0.9813 - acc_top2: 1.0000 - val_loss: 0.0907 - val_acc: 0.9626 - val_acc_top2: 1.0000\n",
      "\n",
      "Epoch 00002: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-06.\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.97074\n",
      "Epoch 3/15\n",
      "5538/5538 [==============================] - 1747s 316ms/step - loss: 0.0209 - acc: 0.9932 - acc_top2: 1.0000 - val_loss: 0.0929 - val_acc: 0.9772 - val_acc_top2: 1.0000\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.97074 to 0.97725, saving model to ./bert_dump/7.hdf5\n",
      "Epoch 4/15\n",
      "5538/5538 [==============================] - 1739s 314ms/step - loss: 0.0132 - acc: 0.9962 - acc_top2: 1.0000 - val_loss: 0.1037 - val_acc: 0.9744 - val_acc_top2: 1.0000\n",
      "\n",
      "Epoch 00004: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-06.\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.97725\n",
      "Epoch 5/15\n",
      "5538/5538 [==============================] - 1734s 313ms/step - loss: 0.0036 - acc: 0.9988 - acc_top2: 1.0000 - val_loss: 0.1184 - val_acc: 0.9825 - val_acc_top2: 1.0000\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.97725 to 0.98253, saving model to ./bert_dump/7.hdf5\n",
      "Epoch 6/15\n",
      "5538/5538 [==============================] - 1734s 313ms/step - loss: 0.0015 - acc: 0.9995 - acc_top2: 1.0000 - val_loss: 0.1633 - val_acc: 0.9805 - val_acc_top2: 1.0000\n",
      "\n",
      "Epoch 00006: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-06.\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.98253\n",
      "Epoch 7/15\n",
      "5538/5538 [==============================] - 1733s 313ms/step - loss: 0.0015 - acc: 0.9997 - acc_top2: 1.0000 - val_loss: 0.1500 - val_acc: 0.9805 - val_acc_top2: 1.0000\n",
      "\n",
      "Epoch 00007: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-07.\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.98253\n",
      "Epoch 8/15\n",
      "5538/5538 [==============================] - 1734s 313ms/step - loss: 3.5612e-04 - acc: 0.9999 - acc_top2: 1.0000 - val_loss: 0.1438 - val_acc: 0.9837 - val_acc_top2: 1.0000\n",
      "\n",
      "Epoch 00008: val_acc improved from 0.98253 to 0.98375, saving model to ./bert_dump/7.hdf5\n",
      "Epoch 9/15\n",
      "5538/5538 [==============================] - 1733s 313ms/step - loss: 1.9256e-04 - acc: 1.0000 - acc_top2: 1.0000 - val_loss: 0.1538 - val_acc: 0.9829 - val_acc_top2: 1.0000\n",
      "\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-07.\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.98375\n",
      "Epoch 10/15\n",
      "5538/5538 [==============================] - 1734s 313ms/step - loss: 2.0088e-04 - acc: 1.0000 - acc_top2: 1.0000 - val_loss: 0.1647 - val_acc: 0.9837 - val_acc_top2: 1.0000\n",
      "\n",
      "Epoch 00010: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-07.\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.98375\n",
      "Epoch 11/15\n",
      "5538/5538 [==============================] - 1734s 313ms/step - loss: 1.1632e-06 - acc: 1.0000 - acc_top2: 1.0000 - val_loss: 0.1662 - val_acc: 0.9833 - val_acc_top2: 1.0000\n",
      "\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-08.\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.98375\n",
      "Epoch 12/15\n",
      "5538/5538 [==============================] - 1738s 314ms/step - loss: 2.6414e-06 - acc: 1.0000 - acc_top2: 1.0000 - val_loss: 0.1678 - val_acc: 0.9846 - val_acc_top2: 1.0000\n",
      "\n",
      "Epoch 00012: val_acc improved from 0.98375 to 0.98456, saving model to ./bert_dump/7.hdf5\n",
      "Epoch 13/15\n",
      "5538/5538 [==============================] - 1729s 312ms/step - loss: 4.0279e-07 - acc: 1.0000 - acc_top2: 1.0000 - val_loss: 0.1734 - val_acc: 0.9842 - val_acc_top2: 1.0000\n",
      "\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-08.\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.98456\n",
      "Epoch 14/15\n",
      "5538/5538 [==============================] - 1730s 312ms/step - loss: 3.9395e-07 - acc: 1.0000 - acc_top2: 1.0000 - val_loss: 0.1751 - val_acc: 0.9842 - val_acc_top2: 1.0000\n",
      "\n",
      "Epoch 00014: ReduceLROnPlateau reducing learning rate to 1.9531249506599124e-08.\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.98456\n",
      "Epoch 15/15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5538/5538 [==============================] - 1748s 316ms/step - loss: 2.6972e-07 - acc: 1.0000 - acc_top2: 1.0000 - val_loss: 0.1761 - val_acc: 0.9842 - val_acc_top2: 1.0000\n",
      "\n",
      "Epoch 00015: ReduceLROnPlateau reducing learning rate to 9.765624753299562e-09.\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.98456\n",
      "616/616 [==============================] - 25s 40ms/step\n",
      "1250/1250 [==============================] - 43s 34ms/step\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "model_2 (Model)                 (None, None, 1024)   324472832   input_1[0][0]                    \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 1024)         0           model_2[1][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 2)            2050        lambda_1[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 324,474,882\n",
      "Trainable params: 324,474,882\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Epoch 1/15\n",
      "5538/5538 [==============================] - 1756s 317ms/step - loss: 0.1473 - acc: 0.9491 - acc_top2: 1.0000 - val_loss: 0.1233 - val_acc: 0.9655 - val_acc_top2: 1.0000\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.96546, saving model to ./bert_dump/8.hdf5\n",
      "Epoch 2/15\n",
      "5538/5538 [==============================] - 1726s 312ms/step - loss: 0.0592 - acc: 0.9813 - acc_top2: 1.0000 - val_loss: 0.0737 - val_acc: 0.9768 - val_acc_top2: 1.0000\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.96546 to 0.97684, saving model to ./bert_dump/8.hdf5\n",
      "Epoch 3/15\n",
      "5538/5538 [==============================] - 1725s 312ms/step - loss: 0.0364 - acc: 0.9892 - acc_top2: 1.0000 - val_loss: 0.0778 - val_acc: 0.9777 - val_acc_top2: 1.0000\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.97684 to 0.97765, saving model to ./bert_dump/8.hdf5\n",
      "Epoch 4/15\n",
      "5538/5538 [==============================] - 1726s 312ms/step - loss: 0.0243 - acc: 0.9929 - acc_top2: 1.0000 - val_loss: 0.0932 - val_acc: 0.9772 - val_acc_top2: 1.0000\n",
      "\n",
      "Epoch 00004: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-06.\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.97765\n",
      "Epoch 5/15\n",
      "5538/5538 [==============================] - 1725s 311ms/step - loss: 0.0085 - acc: 0.9975 - acc_top2: 1.0000 - val_loss: 0.1221 - val_acc: 0.9785 - val_acc_top2: 1.0000\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.97765 to 0.97846, saving model to ./bert_dump/8.hdf5\n",
      "Epoch 6/15\n",
      "5538/5538 [==============================] - 1723s 311ms/step - loss: 0.0072 - acc: 0.9981 - acc_top2: 1.0000 - val_loss: 0.0957 - val_acc: 0.9809 - val_acc_top2: 1.0000\n",
      "\n",
      "Epoch 00006: val_acc improved from 0.97846 to 0.98090, saving model to ./bert_dump/8.hdf5\n",
      "Epoch 7/15\n",
      "5538/5538 [==============================] - 1722s 311ms/step - loss: 0.0046 - acc: 0.9991 - acc_top2: 1.0000 - val_loss: 0.1260 - val_acc: 0.9809 - val_acc_top2: 1.0000\n",
      "\n",
      "Epoch 00007: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-06.\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.98090\n",
      "Epoch 8/15\n",
      "5538/5538 [==============================] - 1721s 311ms/step - loss: 0.0020 - acc: 0.9995 - acc_top2: 1.0000 - val_loss: 0.1904 - val_acc: 0.9785 - val_acc_top2: 1.0000\n",
      "\n",
      "Epoch 00008: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-06.\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.98090\n",
      "Epoch 9/15\n",
      "5538/5538 [==============================] - 1720s 311ms/step - loss: 0.0011 - acc: 0.9999 - acc_top2: 1.0000 - val_loss: 0.1354 - val_acc: 0.9829 - val_acc_top2: 1.0000\n",
      "\n",
      "Epoch 00009: val_acc improved from 0.98090 to 0.98293, saving model to ./bert_dump/8.hdf5\n",
      "Epoch 10/15\n",
      "5538/5538 [==============================] - 1719s 310ms/step - loss: 1.3690e-05 - acc: 1.0000 - acc_top2: 1.0000 - val_loss: 0.1634 - val_acc: 0.9825 - val_acc_top2: 1.0000\n",
      "\n",
      "Epoch 00010: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-07.\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.98293\n",
      "Epoch 11/15\n",
      "5538/5538 [==============================] - 1720s 311ms/step - loss: 8.1648e-05 - acc: 1.0000 - acc_top2: 1.0000 - val_loss: 0.1712 - val_acc: 0.9821 - val_acc_top2: 1.0000\n",
      "\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-07.\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.98293\n",
      "Epoch 12/15\n",
      "5538/5538 [==============================] - 1718s 310ms/step - loss: 6.3319e-07 - acc: 1.0000 - acc_top2: 1.0000 - val_loss: 0.1783 - val_acc: 0.9817 - val_acc_top2: 1.0000\n",
      "\n",
      "Epoch 00012: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-07.\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.98293\n",
      "Epoch 13/15\n",
      "5538/5538 [==============================] - 1719s 310ms/step - loss: 3.6774e-07 - acc: 1.0000 - acc_top2: 1.0000 - val_loss: 0.1843 - val_acc: 0.9813 - val_acc_top2: 1.0000\n",
      "\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-08.\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.98293\n",
      "616/616 [==============================] - 24s 39ms/step\n",
      "1250/1250 [==============================] - 41s 33ms/step\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "model_2 (Model)                 (None, None, 1024)   324472832   input_1[0][0]                    \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 1024)         0           model_2[1][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 2)            2050        lambda_1[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 324,474,882\n",
      "Trainable params: 324,474,882\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Epoch 1/15\n",
      "5538/5538 [==============================] - 1753s 317ms/step - loss: 0.1510 - acc: 0.9450 - acc_top2: 1.0000 - val_loss: 0.0635 - val_acc: 0.9781 - val_acc_top2: 1.0000\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.97806, saving model to ./bert_dump/9.hdf5\n",
      "Epoch 2/15\n",
      "5538/5538 [==============================] - 1724s 311ms/step - loss: 0.0612 - acc: 0.9807 - acc_top2: 1.0000 - val_loss: 0.0776 - val_acc: 0.9760 - val_acc_top2: 1.0000\n",
      "\n",
      "Epoch 00002: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-06.\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.97806\n",
      "Epoch 3/15\n",
      "5538/5538 [==============================] - 1734s 313ms/step - loss: 0.0208 - acc: 0.9937 - acc_top2: 1.0000 - val_loss: 0.0613 - val_acc: 0.9833 - val_acc_top2: 1.0000\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.97806 to 0.98334, saving model to ./bert_dump/9.hdf5\n",
      "Epoch 4/15\n",
      "5538/5538 [==============================] - 1735s 313ms/step - loss: 0.0141 - acc: 0.9959 - acc_top2: 1.0000 - val_loss: 0.0578 - val_acc: 0.9862 - val_acc_top2: 1.0000\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.98334 to 0.98618, saving model to ./bert_dump/9.hdf5\n",
      "Epoch 5/15\n",
      "5538/5538 [==============================] - 1737s 314ms/step - loss: 0.0071 - acc: 0.9978 - acc_top2: 1.0000 - val_loss: 0.0646 - val_acc: 0.9874 - val_acc_top2: 1.0000\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.98618 to 0.98740, saving model to ./bert_dump/9.hdf5\n",
      "Epoch 6/15\n",
      "5538/5538 [==============================] - 1737s 314ms/step - loss: 0.0068 - acc: 0.9982 - acc_top2: 1.0000 - val_loss: 0.0683 - val_acc: 0.9842 - val_acc_top2: 1.0000\n",
      "\n",
      "Epoch 00006: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-06.\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.98740\n",
      "Epoch 7/15\n",
      "5538/5538 [==============================] - 1738s 314ms/step - loss: 0.0022 - acc: 0.9997 - acc_top2: 1.0000 - val_loss: 0.1163 - val_acc: 0.9842 - val_acc_top2: 1.0000\n",
      "\n",
      "Epoch 00007: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-06.\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.98740\n",
      "Epoch 8/15\n",
      "5538/5538 [==============================] - 1741s 314ms/step - loss: 0.0022 - acc: 0.9995 - acc_top2: 1.0000 - val_loss: 0.1133 - val_acc: 0.9866 - val_acc_top2: 1.0000\n",
      "\n",
      "Epoch 00008: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-07.\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.98740\n",
      "Epoch 9/15\n",
      "5538/5538 [==============================] - 1751s 316ms/step - loss: 1.5695e-04 - acc: 1.0000 - acc_top2: 1.0000 - val_loss: 0.1237 - val_acc: 0.9854 - val_acc_top2: 1.0000\n",
      "\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-07.\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.98740\n",
      "616/616 [==============================] - 24s 39ms/step\n",
      "1250/1250 [==============================] - 42s 34ms/step\n"
     ]
    }
   ],
   "source": [
    "train_model_pred, test_model_pred = run_cv(10, DATA_LIST, None, DATA_LIST_TEST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-30T10:18:41.879503Z",
     "start_time": "2019-08-30T10:18:41.776790Z"
    }
   },
   "outputs": [],
   "source": [
    "test_pred = [np.argmax(x) for x in test_model_pred]\n",
    "test_df['labels'] = test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-30T10:18:42.211656Z",
     "start_time": "2019-08-30T10:18:42.185316Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_df[['id', 'labels']].to_csv('baseline3.csv', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-30T10:20:57.406209Z",
     "start_time": "2019-08-30T10:20:57.399812Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# np.save('bert_test_maxlen400_bs16_train.npy', train_model_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dit = {0:'positive',1:'negative'}\n",
    "test_df['labels'] = test_df['labels'].map(dit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df[['id', 'labels']].to_csv('baseline_1.csv', index=None,header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
